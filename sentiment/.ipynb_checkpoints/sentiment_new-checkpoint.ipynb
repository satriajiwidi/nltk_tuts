{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from stopwords import get_stopwords\n",
    "import corpus\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n data positif: 11, n data negatif: 6\n",
      "['suka mobil suka', 'pandang sungguh indah suka', 'bahagia', 'tarik konser', 'sahabat', 'suka makan', 'cinta', 'bahagia', 'olahraga senang', 'asa cerah sejuk', 'dengar musik bahagia', 'tidak suka mobil', 'pandang sungguh tidak bagus', 'sungguh jengkel', 'letih', 'tidak tarik konser', 'musuh']\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(kalimat):\n",
    "    stopwords = get_stopwords()\n",
    "    per_kata = [kata for kata in kalimat.split(' ') if kata not in stopwords]\n",
    "    return ' '.join(per_kata)\n",
    "\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "data = corpus.pos + corpus.neg\n",
    "X = [remove_stopwords(stemmer.stem(kalimat)) for kalimat, _ in data]\n",
    "\n",
    "y = [label for _, label in data]\n",
    "y_vector = [1 if label == 'positive' else 0 for label in y]\n",
    "\n",
    "print('n data positif: {}, n data negatif: {}'.format(len(corpus.pos), len(corpus.neg)))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0]\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.52198783  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.85295293\n",
      "  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "vectorizer_biner = CountVectorizer(binary=True)\n",
    "vectorizer_tf = CountVectorizer(binary=False)\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_vector_biner = vectorizer_biner.fit_transform(X).toarray()\n",
    "X_vector_tf = vectorizer_tf.fit_transform(X).toarray()\n",
    "X_vector_tfidf = vectorizer_tfidf.fit_transform(X).toarray()\n",
    "\n",
    "print(X_vector_biner[0])\n",
    "print(X_vector_tf[0])\n",
    "print(X_vector_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n data setelah resampling: 22\n"
     ]
    }
   ],
   "source": [
    "# oversampling\n",
    "X_vector_biner_resampled, y_resampled = SMOTE().fit_sample(X_vector_biner, y_vector)\n",
    "X_vector_tf_resampled, y_resampled = SMOTE().fit_sample(X_vector_tf, y_vector)\n",
    "X_vector_tfidf_resampled, y_resampled = SMOTE().fit_sample(X_vector_tfidf, y_vector)\n",
    "\n",
    "print('n data setelah resampling:', len(X_vector_biner_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "[[1 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_bayes = GaussianNB()\n",
    "clf_svm = SVC()\n",
    "clf_logres = LogisticRegression()\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# shuffling\n",
    "from random import shuffle\n",
    "temp = list(zip(X_vector_biner_resampled, y_resampled))\n",
    "shuffle(temp)\n",
    "X_vector_biner_resampled, y_resampled1 = zip(*temp)\n",
    "\n",
    "temp = list(zip(X_vector_tf_resampled, y_resampled))\n",
    "shuffle(temp)\n",
    "X_vector_tf_resampled, y_resampled2 = zip(*temp)\n",
    "\n",
    "temp = list(zip(X_vector_tfidf_resampled, y_resampled))\n",
    "shuffle(temp)\n",
    "X_vector_tfidf_resampled, y_resampled3 = zip(*temp)\n",
    "\n",
    "# testing\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf_bayes.fit(X_vector_tfidf_resampled[:19], y_resampled1[:19])\n",
    "pred = clf_bayes.predict(X_vector_tfidf_resampled[19:])\n",
    "print(accuracy_score(y_resampled1[19:], pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_resampled1[19:], pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
